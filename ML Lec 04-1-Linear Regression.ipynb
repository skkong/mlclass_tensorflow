{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "```\n",
    "by Seokkyu Kong\n",
    "Date: 2016-05-02\n",
    "```\n",
    "\n",
    "참고 자료: 1 [모두를 위한 머신러닝/딥러닝 강의 - 홍콩과기대 김성훈교수님](http://hunkim.github.io/ml/)\n",
    "\n",
    "참고 자료: 2, ML lab 04 - multi-variable linear regression을 TensorFlow에서 구현하기  \n",
    "https://www.youtube.com/watch?v=iEaVR1N8EEk&feature=youtu.be\n",
    "\n",
    "위의 강좌 랩에서 다변량 선형 회귀에 대한 tensorflow 활용예제가 나온다.\n",
    "위의 예제를 활용해서 코세라 머신러닝 강좌 1의 다변량 선형 회귀 연습문제에 적용해서 결과값을 서로 비교해 본다.\n",
    "\n",
    "한 가지 주의할 점은 김성훈교수님의 강의 랩에서는 training set 의 입력이 nxm 형태이며 bias term 이 파일 자료에 포함되어 있다. 여기서 m은 training 데이터의 갯수이며, n은 feature 갯수이다. 이런 데이터 처리는 np.loadtxt('xxx', unpack=True, dtype='flat32') 와 같이 unpack=True 지정으로 가능하다.\n",
    "\n",
    "위와 같은 nxm 차원의 데이터는 코세라 연습문제와 같은 mxn 포맷이 아니라서 헷갈린다.\n",
    "\n",
    "따라서 기존 예제와 달리 아래 내용을 변경해본다.\n",
    "\n",
    "- training dataset 은 mxn 으로 읽어서 처리한다. \n",
    "- bias term을 포함시킨다.\n",
    "- 정규화를 적용한다. featureNormalize()는 코세라 연습문제에서 빌어온다.\n",
    "- 새로운 test dataset을 예측하기 위해 placeholder를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['step']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  Tensor(\"Print_26:0\", shape=(?, 3), dtype=float32)\n",
      "Y:  Tensor(\"Print_27:0\", shape=(?, 1), dtype=float32)\n",
      "W:  Tensor(\"Print_28:0\", shape=(3, 1), dtype=float32)\n",
      "hypothesis:  Tensor(\"Print_29:0\", shape=(?, 1), dtype=float32)\n",
      "cost:  Tensor(\"Print_30:0\", shape=(), dtype=float32)\n",
      "\n",
      "0 8.46207e+10 [[ 68082.7890625 ]\n",
      " [ 21152.26953125]\n",
      " [ 10942.15039062]]\n",
      "20 4.15825e+09 [[ 337272.90625   ]\n",
      " [ 101045.640625  ]\n",
      " [   1783.82861328]]\n",
      "40 4.08811e+09 [[ 340376.46875  ]\n",
      " [ 108119.8046875]\n",
      " [  -5250.390625 ]]\n",
      "60 4.0866e+09 [[ 340412.21875   ]\n",
      " [ 109237.40625   ]\n",
      " [  -6367.96630859]]\n",
      "80 4.08656e+09 [[ 340412.625     ]\n",
      " [ 109414.453125  ]\n",
      " [  -6545.02148438]]\n",
      "100 4.08656e+09 [[ 340412.625     ]\n",
      " [ 109442.5078125 ]\n",
      " [  -6573.07177734]]\n",
      "Predicted price of a 1650 sq-ft, 3 br house (using gradient descent): \n",
      "price =  [[ 293082.5625]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def featureNormalize(X):\n",
    "    \"\"\"\n",
    "    피쳐 정규화 함수: 각각의 피쳐는 단위가 다르기 때문에 평균이 0이고 표준편차가 1인\n",
    "    정규화 값으로 변환된다.\n",
    "    \"\"\"\n",
    "    X_norm = X\n",
    "    n = np.size(X, 1)\n",
    "    mu = np.zeros((1, n))\n",
    "    sigma = np.zeros((1, n))\n",
    "    \n",
    "    # 0은 column 단위 연산, 1은 row 단위 연산 적용\n",
    "    m = np.size(X, 0)\n",
    "    mu = mean(X_norm, 0)\n",
    "    sigma = std(X_norm, 0)\n",
    "    \n",
    "    X_norm = (X_norm - mu) / sigma\n",
    "    \n",
    "    return X_norm, mu, sigma\n",
    "\n",
    "\"\"\"\n",
    "# 기존 김성훈교수님 강의 랩에서 데이터를 읽어 들이는 방식\n",
    "\n",
    "xy = np.loadtxt('train.txt', unpack=True, dtype='float32')\n",
    "\n",
    "x_data = xy[0:-1]\n",
    "y_data = xy[-1]\n",
    "\"\"\"\n",
    "\n",
    "# mxn 으로 데이터를 읽어들어서 처리한다.\n",
    "xy = np.loadtxt('ex1data2.txt', dtype='float32', delimiter = ',')\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, -1]\n",
    "\n",
    "# 정규화를 수행한다.\n",
    "X_norm, mu, sigma = featureNormalize(x_data)\n",
    "\n",
    "m = x_data.shape[0] # 자료의 갯수\n",
    "\n",
    "x_data = np.column_stack((np.ones(m), X_norm)) # bias column vector 추가\n",
    "y_data = y_data.reshape((m, 1)) # y_data dimension을 mx1로 맞추어 준다.\n",
    "\n",
    "m, n = x_data.shape\n",
    "\n",
    "# X,Y 에 대한 placeholder 선언\n",
    "X = tf.placeholder(tf.float32, [None, n]) # X: mxn dimension\n",
    "Y = tf.placeholder(tf.float32, [None, 1]) # Y: mx1 dimension\n",
    "\n",
    "# 파라미터 초기화 (구하고자 하는 대상 값임)\n",
    "W = tf.Variable(tf.random_uniform([n, 1], -1.0, 1.0)) # nx1, OK\n",
    "#W = tf.Variable(tf.zeros([3, 1])) # OK\n",
    "\n",
    "# 가설함수 정의, X, W의 순서를 생각해라.\n",
    "hypothesis = tf.matmul(X, W)\n",
    "\n",
    "# cost function 정의\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "print \"X: \", tf.Print(X, [X])\n",
    "print \"Y: \", tf.Print(Y, [Y])\n",
    "print \"W: \", tf.Print(W, [W])\n",
    "print \"hypothesis: \", tf.Print(hypothesis, [hypothesis])\n",
    "print \"cost: \", tf.Print(cost, [cost])\n",
    "print \n",
    "\n",
    "# 제곱합 최소화 하기\n",
    "# learning rate alpha 값을 다르게 하면서 cost J의 변화 정도를 \n",
    "# 그래프로 확인해본다.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# 변수 초기화\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Graph 시작\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "# cost function이 최소가 되는 파라미터 W를 찾는다.\n",
    "for step in xrange(101):\n",
    "    sess.run(train, feed_dict = {X: x_data, Y: y_data})\n",
    "    if step % 20 == 0:\n",
    "        print step, sess.run(cost, feed_dict = {X: x_data, Y: y_data})  \\\n",
    "            , sess.run(W, feed_dict = {X: x_data, Y: y_data})\n",
    "    \n",
    "# 1650 평방피트, 방 3개의 가격을 예측한다.\n",
    "x_test = np.array([1650, 3])\n",
    "# 정규화 시킨다.\n",
    "x_test = (x_test - mu) / sigma\n",
    "\n",
    "x_test = np.append(1, x_test)\n",
    "x_test = x_test.reshape((1, 3))\n",
    "\n",
    "print \"Predicted price of a 1650 sq-ft, 3 br house (using gradient descent): \"\n",
    "print \"price = \", sess.run(hypothesis, feed_dict = {X: x_test})\n",
    "\n",
    "\"\"\"\n",
    "In Octave/MATLAB: \n",
    "\n",
    "best theta for gradient descent... \n",
    "theta =\n",
    "\n",
    "   3.3866e+05\n",
    "   1.0413e+05\n",
    "  -1.7221e+02\n",
    "\n",
    "Predicted price of a 1650 sq-ft, 3 br house (using gradient descent):\n",
    " $292748.085232\n",
    "\"\"\"\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
