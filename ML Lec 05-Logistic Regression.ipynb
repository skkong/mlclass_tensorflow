{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary \n",
    "\n",
    "## Lecture 05 - Logistic Regression Classification Lab\n",
    "\n",
    "```\n",
    "by Seokkyu Kong\n",
    "Date: 2016-05-05\n",
    "```\n",
    "\n",
    "참고 자료: 1 [모두를 위한 머신러닝/딥러닝 강의 - 홍콩과기대 김성훈교수님](http://hunkim.github.io/ml/)\n",
    "\n",
    "참고 자료: 2, ML lab 05 - logistic regression classification을 TensorFlow에서 구현하기  \n",
    "https://www.youtube.com/watch?v=t7Y9luCNzzE&feature=youtu.be\n",
    "\n",
    "기존 랩에서는 train.txt 테스트 데이터를 사용한다. 여기서는 코세라의 연습문제 2번 자료를 이용해서 동일한 결과를 얻는지 비교해 본다.\n",
    "\n",
    "따라서 기존 예제와 달리 아래 내용을 변경해본다.\n",
    "\n",
    "- training dataset 은 mxn 으로 읽어서 처리한다. \n",
    "- bias term을 포함시킨다.\n",
    "- 정규화를 적용한다. featureNormalize()는 코세라 연습문제에서 빌어온다.\n",
    "- 새로운 test dataset을 예측하기 위해 placeholder를 사용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def featureNormalize(X):\n",
    "    \"\"\"\n",
    "    피쳐 정규화 함수: 각각의 피쳐는 단위가 다르기 때문에 평균이 0이고 표준편차가 1인\n",
    "    정규화 값으로 변환된다.\n",
    "    \"\"\"\n",
    "    X_norm = X\n",
    "    n = np.size(X, 1)\n",
    "    mu = np.zeros((1, n))\n",
    "    sigma = np.zeros((1, n))\n",
    "    \n",
    "    # 0은 column 단위 연산, 1은 row 단위 연산 적용\n",
    "    m = np.size(X, 0)\n",
    "    mu = mean(X_norm, 0)\n",
    "    sigma = std(X_norm, 0)\n",
    "    \n",
    "    X_norm = (X_norm - mu) / sigma\n",
    "    \n",
    "    return X_norm, mu, sigma\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1096 [[ 0.14191668]\n",
      " [-0.71575236]\n",
      " [-0.53954476]]\n",
      "1000 0.210739 [[ 1.26506793]\n",
      " [ 3.03555417]\n",
      " [ 2.80028582]]\n",
      "2000 0.204949 [[ 1.50311053]\n",
      " [ 3.53548336]\n",
      " [ 3.28282404]]\n",
      "3000 0.203873 [[ 1.60632622]\n",
      " [ 3.7540462 ]\n",
      " [ 3.49415898]]\n",
      "4000 0.203605 [[ 1.65790582]\n",
      " [ 3.86370397]\n",
      " [ 3.60023761]]\n",
      "5000 0.20353 [[ 1.68518412]\n",
      " [ 3.92181396]\n",
      " [ 3.65646052]]\n",
      "6000 0.203507 [[ 1.70000648]\n",
      " [ 3.95342374]\n",
      " [ 3.68704629]]\n",
      "For a student with scores 45 and 85, we predict an admission probability of 0.773648\n",
      "Train Accuracy: 89.000000\n"
     ]
    }
   ],
   "source": [
    "## Part 1: 데이터 로드\n",
    "# -------------------------\n",
    "xy = np.loadtxt('ex2data1.txt', delimiter=',')\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, -1]\n",
    "\n",
    "m = x_data.shape[0]\n",
    "\n",
    "# XXX: tensorflow는 x 입력값을 normalize 하는게 중요하다.\n",
    "# XXX: 이것때문에 하루 날렸다. -_-;\n",
    "x_data, mu, sigma = featureNormalize(x_data)\n",
    "\n",
    "\n",
    "# bias 1 column 벡터 추가\n",
    "x_data = np.column_stack((np.ones(m), x_data)) # x_data: m x n\n",
    "y_data = y_data.reshape((m, 1)) # y_data: m x 1\n",
    "\n",
    "n = x_data.shape[1]\n",
    "\n",
    "#print x_data[0:5, :]\n",
    "#print y_data[0:5, :]\n",
    "#print m, n\n",
    "\n",
    "\n",
    "## Part 2: 변수, 가설함수, cost function 및 gradient descent 정의\n",
    "# ----------------------------------------------------------------\n",
    "# X, Y 입력 변수 설정\n",
    "X = tf.placeholder(tf.float32, [None, n])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "# 가중치 변수 설정\n",
    "W = tf.Variable(tf.random_uniform([n, 1], -1, 1)) # W: n x 1\n",
    "\n",
    "# 가설 함수 구성\n",
    "h = tf.matmul(X, W)\n",
    "#hypothesis = tf.div(1., 1. + tf.exp(-h)) # OK, XXX: float32 계산으로 맞추기 위해서 1. 을 사용한다.\n",
    "hypothesis = 1. / (1. + tf.exp(-h))\n",
    "\n",
    "\n",
    "# cost function 구성\n",
    "# XXX: +- 부호 구분을 잘해야 한다. 이것때문에 하루 종일 헤맸다. -_-;\n",
    "# XXX: lab에서는 - 부호를 맨 앞으로 빼고 안의 수식은 +로 대체했다.\n",
    "cost = tf.reduce_mean(-Y * tf.log(hypothesis) - (1 - Y) * tf.log(1 - hypothesis))\n",
    "\n",
    "\n",
    "# gradient descent 정의\n",
    "a = tf.Variable(0.1) # learning rate\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "# 변수 초기화 및 그래프 시작\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "# debug\n",
    "#print \"X: \", tf.Print(X, [X])\n",
    "#print \"Y: \", tf.Print(Y, [Y])\n",
    "#print \"W: \", tf.Print(W, [W])\n",
    "#print \"hypothesis: \", tf.Print(hypothesis, [hypothesis])\n",
    "#print \"cost: \", tf.Print(cost, [cost])\n",
    "#print\n",
    "\n",
    "#W = tf.Variable(np.zeros([n, 1]))\n",
    "#W = tf.Variable([[-25.1613187],    [0.20623159],   [0.20147149]])\n",
    "#print sess.run(hypothesis, feed_dict={X: [[0, 0, 0]]})\n",
    "#print sess.run(train, feed_dict={X: [[0, 0, 0]], Y: [[0]]})\n",
    "#print sess.run(cost, feed_dict={X: [[0, 0, 0]], Y: [[0]]})\n",
    "#print sess.run(train, feed_dict={X: [[0, 0, 0]], Y: [[0]]})\n",
    "\n",
    "\n",
    "## Part 3: training dataset\n",
    "# ------------------------------\n",
    "for step in xrange(6001):\n",
    "    sess.run(train, feed_dict = {X: x_data, Y: y_data})\n",
    "    if step % 1000 == 0:\n",
    "        print step, sess.run(cost, feed_dict = {X: x_data, Y: y_data}), sess.run(W)\n",
    "    \n",
    "\n",
    "## Part 4: training set에 대한 모델의 정확도를 계산한다.\n",
    "# -----------------------------------------------------\n",
    "# exam 1의 점수 45점과 exam 2의 점수 85점을 받은 학생에 대해서 예측한다.\n",
    "# XXX: 입력 자료는 항상 normalize 해야 한다.\n",
    "newdata = np.array([45., 85.])\n",
    "newdata = (newdata - mu) / sigma # normalize\n",
    "newdata = np.append(1, newdata) # bias term 추가\n",
    "newdata = newdata.reshape(1, 3) # 1x3 dimension\n",
    "prob = sess.run(hypothesis, feed_dict = {X: newdata}) # predict\n",
    "print('For a student with scores 45 and 85, we predict an admission probability of %f' % prob)\n",
    "\n",
    "\n",
    "# XXX: 계산된 p 값은 차원이 100x1이다. y_data: 100x1\n",
    "p = sess.run(hypothesis, feed_dict = {X: x_data}) >= 0.5 # p: 100 x 1\n",
    "print('Train Accuracy: %f' % (np.mean(double(p == y_data) * 100)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 결론\n",
    "\n",
    "코세라 연습문제의 정확도가 89% 나왔다. 동일한 결론을 얻었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data:  (3, 100)\n",
      "0 0.892219 [[-0.49288213 -0.43764073  0.10852837]]\n",
      "1000 0.210631 [[ 1.26809251  3.04188609  2.80638504]]\n",
      "2000 0.204933 [[ 1.50428498  3.53796244  3.28522062]]\n",
      "3000 0.203869 [[ 1.60688984  3.75524306  3.49531674]]\n",
      "4000 0.203604 [[ 1.65819836  3.86432648  3.60083985]]\n",
      "5000 0.203529 [[ 1.6853416   3.92214966  3.65678549]]\n",
      "6000 0.203507 [[ 1.70009303  3.95360827  3.68722463]]\n",
      "Train Accuracy: 89.000000\n"
     ]
    }
   ],
   "source": [
    "#xy = np.loadtxt('lab05-train.txt', unpack=True, dtype='float32')\n",
    "#xy = np.loadtxt('ex2data1.txt', unpack=True, dtype='float32', delimiter=',')\n",
    "#x_data = xy[0:-1]\n",
    "#y_data = xy[-1]\n",
    "\n",
    "#n = x_data.shape[1]\n",
    "\n",
    "#x_data = np.hstack((np.ones(n), x_data))\n",
    "\n",
    "xy = np.loadtxt('ex2data1.txt', delimiter=',')\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, -1]\n",
    "\n",
    "x_data, mu, sigma = featureNormalize(x_data)\n",
    "\n",
    "x_data = np.column_stack((np.ones(x_data.shape[0]), x_data))\n",
    "x_data = x_data.T\n",
    "\n",
    "print \"x_data: \", x_data.shape\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1, len(x_data)], -1.0, 1.0))\n",
    "\n",
    "h = tf.matmul(W, X)\n",
    "hypothesis = tf.div(1., 1. + tf.exp(-h))\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# debug\n",
    "#print \"X: \", tf.Print(X, [X])\n",
    "#print \"Y: \", tf.Print(Y, [Y])\n",
    "#print \"W: \", tf.Print(W, [W])\n",
    "#print \"h: \", tf.Print(h, [h])\n",
    "#print \"hypothesis: \", tf.Print(hypothesis, [hypothesis])\n",
    "#print \"cost: \", tf.Print(cost, [cost])\n",
    "#print\n",
    "\n",
    "for step in xrange(6001):\n",
    "    sess.run(train, feed_dict = {X: x_data, Y: y_data})\n",
    "    if step % 1000 == 0:\n",
    "        print step, sess.run(cost, feed_dict={X: x_data, Y:y_data}), sess.run(W)\n",
    "\n",
    "# training set에 대한 모델의 정확도를 계산한다.\n",
    "p = sess.run(hypothesis, feed_dict = {X: x_data, Y: y_data}) >= 0.5\n",
    "\n",
    "#y_data2 = y_data.flatten().astype(int)\n",
    "print('Train Accuracy: %f' % (np.mean(double(p == y_data) * 100)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
